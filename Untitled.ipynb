{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some basic libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    def __init__(self,visualization=True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    \n",
    "    def fit(self,data):\n",
    "        #train with data\n",
    "        self.data = data\n",
    "        # { |\\w\\|:{w,b}}\n",
    "        opt_dict = {}\n",
    "        \n",
    "        transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "        \n",
    "        all_data = np.array([])\n",
    "        for yi in self.data:\n",
    "            all_data = np.append(all_data,self.data[yi])\n",
    "        print(all_data)\n",
    "        \"\"\"           \n",
    "        self.max_feature_value = max(all_data)         \n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        \n",
    "        #with smaller steps our margins and db will be more precise\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      #point of expense\n",
    "                      self.max_feature_value * 0.001,]\n",
    "        \n",
    "        #extremly expensise\n",
    "        b_range_multiple = 5\n",
    "        #we dont need to take as small step as w\n",
    "        b_multiple = 5\n",
    "        \n",
    "        latest_optimum = self.max_feature_value*10\n",
    "        \n",
    "        \n",
    "        objective is to satisfy yi(x.w)+b>=1 for all training dataset such that ||w|| is minimum\n",
    "        for this we will start with random w, and try to satisfy it with making b bigger and bigger\n",
    "        \n",
    "        #making step smaller and smaller to get precise value\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            \n",
    "            #we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*self.max_feature_value*b_range_multiple,\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        \n",
    "                        #weakest link in SVM fundamentally\n",
    "                        #SMO attempts to fix this a bit\n",
    "                        # ti(xi.w+b) >=1\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b)>=1:\n",
    "                                    found_option=False\n",
    "                        if found_option:\n",
    "                            \n",
    "                            all points in dataset satisfy y(w.x)+b>=1 for this cuurent w_t, b\n",
    "                            then put w,b in dict with ||w|| as key\n",
    "                            \n",
    "                            opt_dict[np.linalg.norm(w_t)]=[w_t,b]\n",
    "                \n",
    "                #after w[0] or w[1]<0 then values of w starts repeating itself because of transformation\n",
    "                #Think about it, it is easy\n",
    "                #print(w,len(opt_dict)) Try printing to understand\n",
    "                if w[0]<0:\n",
    "                    optimized=True\n",
    "                    print(\"optimized a step\")\n",
    "                else:\n",
    "                    w = w-step\n",
    "                    \n",
    "            # sorting ||w|| to put the smallest ||w|| at poition 0 \n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #optimal values of w,b\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "\n",
    "            self.w=opt_choice[0]\n",
    "            self.b=opt_choice[1]\n",
    "            \n",
    "            #start with new latest_optimum (initial values for w)\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "        \n",
    "            \"\"\"\n",
    "    def predict(self,features):\n",
    "        #sign(x.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification!=0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*',c=self.colors[classification])\n",
    "        return (classification,np.dot(np.array(features),self.w)+self.b)\n",
    "    \n",
    "    def visualize(self):\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,c=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        \n",
    "        # hyperplane = x.w+b (actually its a line)\n",
    "        # v = x0.w0+x1.w1+b -> x1 = (v-w[0].x[0]-b)/w1\n",
    "        #psv = 1     psv line ->  x.w+b = 1a small value of b we will increase it later\n",
    "        #nsv = -1    nsv line ->  x.w+b = -1\n",
    "        # dec = 0    db line  ->  x.w+b = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            #returns a x2 value on line when given x1\n",
    "            return (-w[0]*x-b+v)/w[1]\n",
    "       \n",
    "        hyp_x_min= self.min_feature_value*0.9\n",
    "        hyp_x_max = self.max_feature_value*1.1\n",
    "        \n",
    "        # (w.x+b)=1\n",
    "        # positive support vector hyperplane\n",
    "        pav1 = hyperplane(hyp_x_min,self.w,self.b,1)\n",
    "        pav2 = hyperplane(hyp_x_max,self.w,self.b,1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[pav1,pav2],'k')\n",
    "        \n",
    "        # (w.x+b)=-1\n",
    "        # negative support vector hyperplane\n",
    "        nav1 = hyperplane(hyp_x_min,self.w,self.b,-1)\n",
    "        nav2 = hyperplane(hyp_x_max,self.w,self.b,-1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nav1,nav2],'k')\n",
    "        \n",
    "        # (w.x+b)=0\n",
    "        # db support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min,self.w,self.b,0)\n",
    "        db2 = hyperplane(hyp_x_max,self.w,self.b,0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2],'y--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  7.  2.  8.  3.  8.  5.  1.  6. -1.  7.  3.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining a basic data\n",
    "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),1:np.array([[5,1],[6,-1],[7,3]])}\n",
    "svm = SVM() # Linear Kernel\n",
    "svm.fit(data=data_dict)\n",
    "#svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
